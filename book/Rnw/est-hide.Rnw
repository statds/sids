Let's set up a true $\mu$ that no one knows and generate a random sample of size
$n = 20$.
<<hide-normal-setup, eval=TRUE, >>=
set.seed(123) # each student can contribute a digit to make mu really unknown
mu <- runif(1, min =- 10, max = 10)
n <- 20
x <- rnorm(n, mean = mu, sd = 1)
summary(x)
@ 


\paragraph{Estimators}

Let us consider a few candidate estimators

\begin{itemize}
\item Sample mean
\item Sample median
\item Midrange
\end{itemize}

The three estimates based on the observed sample are
<<hide-normal-one>>=
(estimates <- c(mu1 = mean(x), mu2 = median(x), mu3 = mean(range(x))))
@ 


\paragraph{Mean Squared Error}

To assess which estimator is better, we compare them with the true value of
$\mu$. The squared error of an estimator $\hat\mu$ of $\mu$ is
$(\hat\mu - \mu)^2$.
For the three estimates based on the given sample, we have:
<<hide-normal-mse>>=
(estimates - mu)^2
@ 


Note that this comparison is for only the given sample. A good estimator may by
chance behaves worse than a bad estimator. A real assessment of the quality of
the estimator should be based on a large number of replicates, where we can
check which estimator performs the best on average. To do so, we need to play
this game repeatedly, collect the squared errors of the estimators, and compare
their means, that is, mean squared error.


\begin{illustration}[Hide-and-seek with a normal population]
Now the game becomes a racing game. We do it through a simulation study.
Let us construct a function to do replicate of such game.
<<hide-normal-do1rep>>=
do1rep <- function(n, mu) {
    ## generate data
    x <- rnorm(n, mean = mu, sd = 1)
    ## collect estimates
    est <-  c(mu1 = mean(x), mu2 = median(x), mu3 = mean(range(x)))
    ## return squared error
    return((est - mu)^2)
}

@

Each time we call this function, the experiment is done and the squared errors
of the three estimators are returned.
<<hide-normal-do1rep-run>>=
do1rep(n, mu)
do1rep(n, mu)
@ 



Which estimator is winning the game? Let's repeat the experiment 1000 times and
compare the MSE.
<<hide-normal-sim>>=
nrep <- 1000
sim <- replicate(nrep, do1rep(n, mu))
rowMeans(sim)
@ 


The first estimator, the sample mean, is a clear winner!
\end{illustration}

\begin{illustration}[Hide-and-seek with a Cauchy population]
  % \indexExSix{Computing ranks in the presence of ties}
\label{example:has-cauchy}
Now let's change the distribution of the population from normal to Cauchy.
<<hide-cauchy>>=
set.seed(1979)
mu <- runif(1, min =- 10, max = 10)
x <- rcauchy(n, location = mu)
summary(x)

do1rep <- function(n, mu) {
    ## generate data
    x <- rcauchy(n, location = mu)
    ## collect estimates
    est <-  c(mu1 = mean(x), mu2 = median(x), mu3 = mean(range(x)))
    ## return squared error
    return((est - mu)^2)
}

sim <- replicate(nrep, do1rep(n, mu))
rowMeans(sim)
@
Which estimator is the winner this time?
\end{illustration}


\begin{illustration}[Hide-and-seek with a uniform population]
  % \indexExSix{Computing ranks in the presence of ties}
\label{example:has-unif}
Now let's change the distribution of the population to one with light tails.
<<hide-unif>>=
set.seed(1975)
mu <- runif(1, min =- 10, max = 10)
x <- runif(n, mu - 1, mu + 1)
summary(x)

do1rep <- function(n, mu) {
    ## generate data
    x <- runif(n, mu - 1, mu + 1)
    ## collect estimates
    est <-  c(mu1 = mean(x), mu2 = median(x), mu3 = mean(range(x)))
    ## return squared error
    return((est - mu)^2)
}

sim <- replicate(nrep, do1rep(n, mu))
rowMeans(sim)
@
Which estimator is the winner this time?
\end{illustration}


Can we find an estimator that performs the best in all scenarios?

Now that the performance depends on the true population which is
unknown, can we make some good guesses and choose one? This is known
as adaptive estimation.