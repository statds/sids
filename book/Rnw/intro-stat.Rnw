
We will introduce some statistical functions to summarize data. To demonstrate some of these functions, let's first generate some data:

<<intro-rexp1, eval=TRUE, >>=
n <- 10000
lambda <- 10
x <- -log(runif(n))/lambda
@ 

Note that in \R, the \code{log} function uses the natural logarithm by default. To use base 10 or base 2, use \code{log10} and \code{log2}, respectively. To specify the base, use the \code{base} argument. For example, try  \code{log(16, base=4)}.

The most commonly used one is the mean (a.k.a. the average), $\overline{x}$:\\
$$\overline{x}=\frac{x_1+\ldots+x_n}{n}\,.$$
Other ways to estimate some sort of `central tendency' of a distribution are:
 \begin{itemize}
 \item The trimmed mean, which is similar to the mean, except that the smallest and largest $p\cdot 100\%$  of the values are excluded from the computation. In our example, if we take $p=0.1$ with the simulated data, only 8,000 data points will be used in the calculation of the trimmed mean; 
 \item The median, which is a number (denoted here by $x_{0.5}$) such that half the data points are greater than $x_{0.5}$ and half are less than or equal to $x_{0.5}$. 
 \end{itemize}

Let's compute the sample's mean, trimmed mean, and median. Notice that  in this example the mean is greater than trimmed mean, which is greater than the median. In general, the mean is not a great estimate of the `center' of a non-symmetric distribution. We say that the mean is more `sensitive to extreme values' than the median.
<<intro-rexp2, eval=TRUE, comment="Output:">>=
mean(x)
mean(x, trim=0.1)
median(x)
@ 

The formula we used to generate the data is the probability function of the exponential distribution, with rate parameter $\lambda=10$. We denote it by $X\sim exp(\lambda)$. The exponential distribution is often used to model random waiting times, like the time between incoming text messages. We would usually generate it by using the \code{rexp()} function in \R.
Mathematical analysis of the distribution leads to the fact that the expected value of an exponential random variable with rate $\lambda$, is $1/\lambda$. We see that the theoretical expected value of our example is 0.1, and the sample mean is very close to 0.1. This is no coincidence - we will discuss it in  later chapter.


The distribution of \texttt{x} is shown below as a \textit{box-and-whisker plot} (or simply, boxplot). This is a very simple representation of numeric data, which is constructed by summarizing the data using a few numeric characteristics. The boxplot below is drawn horizontally, and the vertical grey line inside the box is the median. Similar to the median, we find the first quartile -- a point, $x_{0.25}$, such that 25\% of the values are less than $x_{0.25}$ and 75\% are greater than $x_{25}$; and the third quartile -- a point, $x_{0.75}$, such that 75\% of the values are less than $x_{0.75}$ and 25\% are greater than $x_{0.75}$. The first and third quartiles are the vertical edges of the box, also called the lower and upper hinges. So, the box represents 50\% of the data. The range between the first and third quartiles is called the \textit{Inter-Quartile Range}, or IQR, which is sometimes used to estimate the dispersion or spread of the data.
The `whiskers', which are the dashed grey lines, are constructed by adding 1.5$\cdot$IQR to each side of the box. If the result is smaller than the minimum value (or greater than the maximum), then the whisker only extends to the minimum (maximum). Points within the range between the two whiskers are not plotted individually, since their distribution is summarized succinctly by the box-and-whiskers plot. Points outside the range between the two whiskers are considered `outliers', or extreme values, and are shown explicitly. 

The plot was generated with the following code. Try it, and try changing some of the parameters to understand their role. We will cover the topic of visualization in a different chapter.

<<intro-boxplot-rexp, eval=TRUE, fig.align='center', fig.width=6, fig.height=3, fig.cap="A boxplot." >>=
boxplot(x, cex=0.5, col=4,border = "grey66", horizontal = T, axes=F, at=0.25)
axis(1, pos = 0)
points(mean(x),0.25,col=2, pch=19, cex=0.7)
points(mean(x, trim=0.1),0.25, col="brown", pch=18)
@ 


A boxplot does not include the mean, or the trimmed mean, but we have added them here as a red circle and brown diamond, respectively, in order to show that they are different than the mean. The median is smaller than the mean in this case, so we say that the distribution is skewed to the left. The median does not depend on the scale of the data. It simply represents where half the data lies. 

A more detailed summary of a sample can be obtained by calculating its quantiles. In the boxplot, only three quantiles (also called percentiles) are shown. We can show the quintiles (20, 40, 60, 80 percentiles), or deciles (10, 20,\ldots, 90 percentiles) by using the \code{quantile()} function.

<<intro-quantile-rexp, eval=TRUE, fig.align='center', fig.width=7, fig.height=4, fig.cap="A histogram of a sample from an exponential distribution, with the 10, 20, 30,... percentiles" >>=
hist(x, breaks=50, border="white", col="lightblue", freq=FALSE, xlim=c(0,0.6))
deciles <- quantile(x, probs=seq(0.1,0.9,by=0.1))
abline(v=deciles, lty=2, col="purple", lwd=2)
text(deciles, dexp(deciles, 10), paste0(seq(10,90,by=10),"%"), cex=0.7, col="orange")
@ 


In addition to sample statistics which summarize some notion of the center of the distribution, we are often interested in estimating the dispersion of the data. The most commonly used measures of dispersion are the variance, and its square root - the standard deviation. The variance is defined as follows

$$Var(X)=\frac{(x_1-\mu)^2+\ldots+(x_n-\mu)^2}{n}$$
 where $\mu$ is the mean of the distribution of $X$. In words, the variance is the average squared deviation from the mean.
Notice that in \R the variance is computed with n-1 in the denominator (with n-1 we get an `unbiased estimator' for the true variance).

The corresponding functions in \R are \code{var()} and \code{sd()}. In the following code we also demonstrate the \code{IQR()} function.
<<intro-rexp3, eval=TRUE, comment="Output:">>=
var(x)
sd(x) # note that sd(x) is sqrt(sd(x))
IQR(x)
@ 

We will see in subsequent chapters that the normal distribution plays a major role in statistics. It is defined by a probability density function, with two parameters -- $\mu$ and $\sigma^2$:
$$\phi(x; \mu,\sigma^2)=\frac{1}{\sqrt{2\pi\sigma^2}}\exp\left[-\frac{(x-\mu)^2}{2\sigma^2}\right]\,.$$
It is symmetric, `bell-shaped', and centered around the mean, $\mu$, as shown in the following plot. The blue histogram is generated by the \code{rnorm()} function, using $\mu=2.5$ and $\sigma^2=0.25$. The orange curve shows the function $\phi$, by using the \code{dnorm()} function (to obtain the density of $x$).
<<intro-rnorm1, eval=TRUE, comment="Output:", fig.align='center', fig.width=4, fig.height=4, fig.cap="A histogram of a sample from an normal distribution, with mean=2.5 and variance=0.25" >>=
x <- rnorm(10000, mean=2.5, sd=0.5)
hist(x, breaks=30, border="white", col="navyblue", freq=FALSE)
xs <- seq (0,5, length=500)lines(xs, dnorm(xs,2.5, 0.5), col="orange", lwd=3)
@ 

We can obtained more detailed summaries about the sample, by using the functions \code{summary()} and \code{describe()} (the latter is from the psych package, and provides more details.)

<<intro-rnorm2, eval=TRUE, comment="Output:">>=
print(summary(x))
print(psych::describe(x))
@ 

\code{summary()}  gives the minimum, maximum, the 25th, 50th, and 75th percentiles, as well as the mean of the sample. \code{psych::describe()} also gives the sample size, the standard deviation, the trimmed mean, the mean absolute deviation (mad), the range (maximum minus minimum), the skewness, and the kurtosis \hb{will we use the kurtosis later? If so, we should add a ref.}.

We conclude this chapter with some functions which can be used to summarize discrete (categorical) data, where the mean, variance, quantiles, etc. are not applicable. We will revisit the topic of summarizing data in the chapter on \hb{visualization}.

To simulate categorical data we can use the \code{rmultinom()} function, which simulates putting $N$ objects in $K$ bins with given probabilities. Another possibility is to use \code{cut()} function which divides a range of number into discrete ranges and creates discrete categories in a factor variable.
For example, suppose there is a town with three hotels (Motel 6, Best Western,  and Hilton) with 400, 300, and 300 rooms, and one auto rental company with only two makes of cars (700 Honda, and 300 Teslas). In the following code we simulate the allocation of 100 visitors to hotels and cars. We use the \code{table()} function to show the counts by hotel, by car, and by both. 

<<intro-cut1, eval=TRUE, comment="Output:">>=
hotelrooms <- cut(runif(100),breaks = c(0,0.4,0.7,1), include.lowest = TRUE)
levels(hotelrooms) <- c("Motel 6", "Best Western", "Hilton")
autorental <- cut(runif(100),breaks = c(0,0.7,1), include.lowest = TRUE)
levels(autorental) <- c("Honda", "Tesla")
(hoteltbl <- table(hotelrooms))
(autotbl <- table(autorental))
table(hotelrooms, autorental)
@ 

We can use the \code{max()} and \code{which.max()} functions to find the mode of the data (the most frequent value).

<<intro-cut2, eval=TRUE, comment="Output:">>=
cat(levels(hotelrooms)[which.max(hoteltbl)],":", max(hoteltbl),"\n")
cat(levels(autorental)[which.max(autotbl)],":", max(autotbl),"\n")
@ 

%matrices
% in a chapter on visualization:
%.  more distributions - Poisson, beta, gamma, lognormal
%.  density plot
%.  ecdf
%.  Q-Q plot
%.  scatterplot
